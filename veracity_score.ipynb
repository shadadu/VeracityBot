{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "from spacy import displacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6db86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Download Fake News Dataset (LIAR Dataset)\n",
    "dataset = load_dataset(\"liar\")\n",
    "\n",
    "# Convert dataset to pandas for easy processing\n",
    "df_train = pd.DataFrame(dataset[\"train\"])\n",
    "df_test = pd.DataFrame(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Extract text & veracity labels\n",
    "def preprocess_articles(df):\n",
    "    return [{\"text\": row[\"statement\"], \"label\": row[\"label\"]} for _, row in df.iterrows()]\n",
    "\n",
    "train_data = preprocess_articles(df_train)\n",
    "test_data = preprocess_articles(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270826a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Named Entity Recognition (NER) using spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Open-source NER model\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {ent.text: ent.label_ for ent in doc.ents}  # Extract entities\n",
    "    return entities\n",
    "\n",
    "# Example NER extraction\n",
    "sample_text = train_data[0][\"text\"]\n",
    "print(\"NER Entities:\", extract_entities(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ef1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ Query Diffbot Knowledge Graph for factual validation\n",
    "DIFFBOT_TOKEN = \"YOUR_DIFFBOT_API_KEY\"\n",
    "\n",
    "def query_diffbot(entity_name):\n",
    "    url = f\"https://kg.diffbot.com/kg/v3/enhance?token={DIFFBOT_TOKEN}&name={entity_name}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.text)\n",
    "    return None\n",
    "\n",
    "# Fetch factual data for each article\n",
    "def enrich_with_kg(text):\n",
    "    entities = extract_entities(text)\n",
    "    knowledge_results = []\n",
    "    for entity in entities.keys():\n",
    "        kg_data = query_diffbot(entity)\n",
    "        if kg_data:\n",
    "            knowledge_results.append(json.dumps(kg_data))\n",
    "    return text + \" \" + \" \".join(knowledge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a6d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5Ô∏è‚É£ Generate article + KG knowledge dataset\n",
    "train_augmented = [{\"text\": enrich_with_kg(item[\"text\"]), \"label\": item[\"label\"]} for item in train_data]\n",
    "test_augmented = [{\"text\": enrich_with_kg(item[\"text\"]), \"label\": item[\"label\"]} for item in test_data]\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df_train_aug = pd.DataFrame(train_augmented)\n",
    "df_test_aug = pd.DataFrame(test_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6Ô∏è‚É£ Train Deep Learning Model (DistilBERT for Fake News Detection)\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=6)  # LIAR dataset has 6 labels\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset\n",
    "train_dataset = df_train_aug.map(tokenize_data)\n",
    "test_dataset = df_test_aug.map(tokenize_data)\n",
    "\n",
    "# Convert to PyTorch dataset\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8634b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fake_news_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b950a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model(\"./fake_news_model\")\n",
    "tokenizer.save_pretrained(\"./fake_news_model\")\n",
    "\n",
    "print(\"Fake News Detection Model Training Complete! üöÄ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
